{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Importing necessary libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nfrom nltk.stem import WordNetLemmatizer ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"wine_df=pd.read_csv('../input/wine-reviews/winemag-data-130k-v2.csv')\nwine_df.drop(columns= ['Unnamed: 0']); # Dropping extra column with non important imformation","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top 5 countries that produce most number of wines"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.countplot(wine_df['country'],order=wine_df.country.value_counts().iloc[:5].index)\nplt.xticks(rotation=90)\nplt.xlabel('Country')\nplt.ylabel('Number of wines produced')\nplt.title(\"Top 5 countries with largest number of wines produced\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## U.S.A. makes more number of wines than all the next top 4 producers"},{"metadata":{},"cell_type":"markdown","source":"## Let us find out which of all the countries make best wines based on the point "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making a function to get the average of the points of wines of a particular country\navg_country_score=pd.DataFrame(columns=['country','points'])\ndef points():\n    score=[]\n    for i in set(wine_df.country):\n        score.append(wine_df[wine_df['country']==i]['points'].mean())\n    return score\nscore=points()\navg_country_score['country']=list(set(wine_df.country))\navg_country_score['points']=score\navg_country_score.dropna(inplace=True)\navg_country_score=avg_country_score.sort_values('points',ascending=False)\navg_country_score.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.barplot(data=avg_country_score.head(),x='country',y='points')\nplt.xticks(rotation=90)\nplt.xlabel(\"Country\")\nplt.ylabel(\"Average of points for all the wines\")\nplt.title(\"Top 5 countries with best testing wines\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## On average best testing wines can be found in England followed by India and austria"},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing\n\nThe process of converting data to something a computer can understand is referred to as pre-processing. One of the major forms of pre-processing is to filter out useless data. In natural language processing, useless words (data), are referred to as stop words.\n### Stop-words\nStop Words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.\n\nWe would not want these words to take up space in our database, or taking up valuable processing time. For this, we can remove them easily, by storing a list of words that you consider to stop words. NLTK(Natural Language Toolkit) in python has a list of stopwords stored in 16 different languages.\n\n### Tokenizing \nTokenization is the process by which big quantity of text is divided into smaller parts called tokens.\n These tokens are very useful for finding such patterns as well as is considered as a base step for stemming and lemmatization.\n \n### Lemmatize\nLemmatization is the process of grouping together the different inflected forms of a word so they can be analysed as a single item. Lemmatization is similar to stemming but it brings context to the words. So it links words with similar meaning to one word."},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill nan with empty spaces\nwine_df['description']=wine_df['description'].fillna('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This function is to remove stopwords from a particular column and to tokenize it\ndef rem_stopwords_tokenize(data,name):\n      \n    def getting(sen):\n        example_sent = sen\n\n        stop_words = set(stopwords.words('english')) \n\n        word_tokens = word_tokenize(example_sent) \n\n        filtered_sentence = [w for w in word_tokens if not w in stop_words] \n\n        filtered_sentence = [] \n\n        for w in word_tokens: \n            if w not in stop_words: \n                filtered_sentence.append(w) \n        return filtered_sentence\n    x=[]\n    for i in data[name].values:\n        x.append(getting(i))\n    data[name]=x\nrem_stopwords_tokenize(wine_df,'description')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making a function to lemmatize all the words\nlemmatizer = WordNetLemmatizer() \ndef lemmatize_all(data,name):\n    arr=data[name]\n    a=[]\n    for i in arr:\n        b=[]\n        for j in i:\n            x=lemmatizer.lemmatize(j,pos='a')\n            x=lemmatizer.lemmatize(x)\n            b.append(x)\n        a.append(b)\n    data[name]=a\nlemmatize_all(wine_df,'description')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## After all the pre-processing(removing stop words, tokenizing, lammetizing) our data looks something like this"},{"metadata":{"trusted":true},"cell_type":"code","source":"wine_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# saving this transformed dataframe to output\nwine_df.to_csv(\"preprocessed_wine_df.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Recommendation top 5 wines based on the current preferences"},{"metadata":{"trusted":true},"cell_type":"code","source":"# function for matching input from user to the best title from the wine_df\nfrom fuzzywuzzy import process\ndef get_matching_name(input_user, df):\n    str2match = input_user\n    str_options = df.title.to_list()\n    highest = process.extractOne( str2match, str_options )\n    return highest[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_rec_finder_by_popularity(na,df, number = 5):\n    def intersection(lst1, lst2): \n        return list(set(lst1) & set(lst2)) \n    def find_rec(name):\n        x=list(df[df['title']==name]['description'].values)[0]\n        score=[]\n        for i in range(len(df)):\n            score.append([len(intersection(x,df['description'].values[i])),df['title'].values[i]])\n        return score\n    \n    na = get_matching_name(na, df)\n    print(f\"User choice matches {na} from the database \\n\")\n    recommendations=find_rec(na)\n    recommendations.sort(reverse=True)\n    recommendations=np.array(recommendations)\n    ans=recommendations[:number,1]\n    ans2=[]\n    for i in ans:\n        ans2.append([df[df['title']==i]['points'].values[0],i])\n    ans2.sort(reverse=True)\n    ans2=np.array(ans2)\n    ans2=ans2[:10,1]\n    print(f\"Recommended top {number} wines with similar tastes are:- \")\n    for i in ans2:\n        print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=set_rec_finder_by_popularity(\"Vintner's Reserve Wild\",wine_df, number = 5)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}